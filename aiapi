#!/bin/bash
set -e

# Basisverzeichnisse
WORKSPACE="/workspace"
MODEL_DIR="$WORKSPACE/models"
OLLAMA_DIR="$WORKSPACE/ollama"
COMFYUI_DIR="$WORKSPACE/ComfyUI"
SD_DIR="$WORKSPACE/stable-diffusion-webui"
LOG_DIR="$WORKSPACE/logs"

# Erstelle Verzeichnisse falls nicht vorhanden
mkdir -p "$MODEL_DIR" "$OLLAMA_DIR" "$COMFYUI_DIR" "$SD_DIR" "$LOG_DIR"

# Grundlegende Systemaktualisierung
echo "ğŸ”„ Aktualisiere Systempakete..."
apt-get update && apt-get install -y wget git python3.10 python3.10-venv libgl1 pciutils lshw nano

### ğŸ›  Ollama Installation ###
echo "ğŸ“¥ Installiere Ollama..."
pkill -f "ollama" || true  # Beende laufende Ollama-Instanzen
wget -q -O "$OLLAMA_DIR/ollama" https://github.com/ollama/ollama/releases/download/v0.1.37/ollama-linux-amd64
chmod +x "$OLLAMA_DIR/ollama"

# Symlink erstellen, um Ollama von Ã¼berall auszufÃ¼hren
ln -sf "$OLLAMA_DIR/ollama" /usr/local/bin/ollama

# Starte Ollama im Hintergrund
nohup "$OLLAMA_DIR/ollama" serve > "$LOG_DIR/ollama.log" 2>&1 & disown

### ğŸ›  Automatic1111 Stable Diffusion WebUI ###
echo "ğŸ“¥ Installiere Stable Diffusion WebUI..."
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git "$SD_DIR" || true
cd "$SD_DIR"

# ğŸ›  Falls root, Benutzer erstellen
if [ "$EUID" -eq 0 ]; then
    echo "ğŸ”„ Erstelle Benutzer 'sduser', um WebUI als Nicht-Root zu starten..."
    useradd -m -s /bin/bash sduser || true
    chown -R sduser:sduser "$SD_DIR"
fi

# Python-Umgebung einrichten
su - sduser -c "
    cd '$SD_DIR'
    python3.10 -m venv venv
    source venv/bin/activate
    pip install --upgrade pip
    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
    pip install -r requirements.txt
    mkdir -p '$MODEL_DIR/Stable-diffusion'
    export COMMANDLINE_ARGS='--listen --api --port 7860 --ckpt-dir $MODEL_DIR/Stable-diffusion --no-download-sd-model'
    nohup ./webui.sh > '$LOG_DIR/webui.log' 2>&1 & disown
"

### ğŸ›  ComfyUI Installation ###
echo "ğŸ“¥ Installiere ComfyUI..."
git clone https://github.com/comfyanonymous/ComfyUI.git "$COMFYUI_DIR" || true
cd "$COMFYUI_DIR"

# Python Umgebung fÃ¼r ComfyUI
python3.10 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt

# Modelle verlinken (optional)
mkdir -p "$COMFYUI_DIR/models/checkpoints"
ln -s "$MODEL_DIR/Stable-diffusion"/* "$COMFYUI_DIR/models/checkpoints/" 2>/dev/null || true

# Starte ComfyUI
export COMFY_PORT=8188
nohup python main.py --listen --port "$COMFY_PORT" > "$LOG_DIR/comfy.log" 2>&1 & disown

### â³ Wartezeit fÃ¼r Initialisierungen ###
echo "â³ Warte auf Initialisierung (120 Sekunden)..."
sleep 120

### âœ… StatusprÃ¼fung ###
echo -e "\nâœ… Installationsstatus:"
curl -s http://localhost:11434 && echo "âœ… Ollama lÃ¤uft" || echo "âŒ Ollama-Fehler"
curl -s http://localhost:7860 && echo "âœ… Automatic1111 lÃ¤uft" || echo "âŒ Automatic1111 Fehler"
curl -s http://localhost:$COMFY_PORT && echo "âœ… ComfyUI lÃ¤uft" || echo "âŒ ComfyUI Fehler"

### ğŸ“Œ Port-Informationen ###
echo -e "\nğŸ“Œ Ports in RunPod freischalten:"
echo "- Ollama: 11434"
echo "- Automatic1111: 7860"
echo "- ComfyUI: 8188"
echo "- Optional: 3000"

### ğŸŒ API Endpoints ###
echo -e "\nğŸŒ API Endpoints:"
echo "ğŸ”— Ollama API:        http://localhost:11434"
echo "ğŸ”— Automatic1111 API:  http://localhost:7860"
echo "ğŸ”— ComfyUI API:        http://localhost:8188"
